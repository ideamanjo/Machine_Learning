{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKVeLItnS5uV"
   },
   "source": [
    "Copyright (C) 2019 Software Platform Lab, Seoul National University\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "\n",
    "you may not use this file except in compliance with the License. \n",
    "\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software \n",
    "\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
    "\n",
    "\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "\n",
    "See the License for the specific language governing permissions and\n",
    "\n",
    "\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mds1.snu.ac.kr\u001b[m  Tue Nov  5 17:30:10 2019\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m12196\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  167\u001b[m / \u001b[33m12196\u001b[m MB | \u001b[1m\u001b[30mds4user3\u001b[m(\u001b[33m157M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m12196\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m12196\u001b[m MB |\r\n",
      "\u001b[36m[4]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m11849\u001b[m / \u001b[33m12196\u001b[m MB | \u001b[1m\u001b[30mds4user5\u001b[m(\u001b[33m11839M\u001b[m)\r\n",
      "\u001b[36m[5]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m12196\u001b[m MB |\r\n",
      "\u001b[36m[6]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  167\u001b[m / \u001b[33m12196\u001b[m MB | \u001b[1m\u001b[30mds4user7\u001b[m(\u001b[33m157M\u001b[m)\r\n",
      "\u001b[36m[7]\u001b[m \u001b[34mTITAN Xp        \u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m12196\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LQHVwI1g_PF"
   },
   "source": [
    "### Preparing MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8282,
     "status": "ok",
     "timestamp": 1571380185445,
     "user": {
      "displayName": "Gyeong-In Yu",
      "photoUrl": "",
      "userId": "06641939619571661692"
     },
     "user_tz": -540
    },
    "id": "LydTwAzMhHw0",
    "outputId": "3abb39b8-a764-4679-9a0d-d51e35d5400f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Download the mnist dataset using keras\n",
    "data_train, data_test = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Parse images and labels\n",
    "(train_images, train_labels) = data_train\n",
    "(test_images, test_labels) = data_test\n",
    "\n",
    "# Numpy reshape & type casting\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_labels = train_labels.astype('int64')\n",
    "test_labels = test_labels.astype('int64')\n",
    "\n",
    "\n",
    "# Normalizing the images to the range of [0., 1.]\n",
    "train_images /= 255.\n",
    "test_images /= 255.\n",
    "\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Recap\n",
    "\n",
    "Build simple CNN by using TensorFlow `layers` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "    train_ds = train_ds.shuffle(10000)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "    test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "    # create an empty iterator with only type and shape information\n",
    "    iterator = tf.data.Iterator.from_structure(tf.compat.v1.data.get_output_types(train_ds),\n",
    "                                               tf.compat.v1.data.get_output_shapes(train_ds))\n",
    "    x, y = iterator.get_next()\n",
    "\n",
    "    # create an operation for initializing the iterator with the train or test dataset\n",
    "    train_init = iterator.make_initializer(train_ds)\n",
    "    test_init = iterator.make_initializer(test_ds)\n",
    "\n",
    "    x = tf.layers.conv2d(x, 32, [3, 3], activation='relu', padding='same')\n",
    "    x = tf.layers.max_pooling2d(x, [2, 2], [2, 2], padding='same')\n",
    "\n",
    "    x = tf.layers.conv2d(x, 64, [3, 3], activation='relu', padding='same')\n",
    "    x = tf.layers.max_pooling2d(x, [2, 2], [2, 2], padding='same')\n",
    "\n",
    "    x = tf.layers.conv2d(x, 128, [3, 3], activation='relu', padding='same')\n",
    "    x = tf.layers.max_pooling2d(x, [2, 2], [2, 2], padding='same')\n",
    "\n",
    "    x = tf.layers.flatten(x)\n",
    "    x = tf.layers.dense(x, 256, activation='relu')\n",
    "    logits = tf.layers.dense(x, 10)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=y))\n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    num_correct_preds = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(logits, 1), y), tf.int32))\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        sess.run(train_init)\n",
    "        total_loss = 0\n",
    "        total_corrects = 0\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                _, loss_val, corrects_val = sess.run([train_op, loss, num_correct_preds])\n",
    "                total_loss += loss_val\n",
    "                total_corrects += corrects_val\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        print('Epoch: %02d' % (epoch + 1),\n",
    "              'Loss = {:2.4f}'.format(total_loss * batch_size / 60000),\n",
    "              'Train accuracy = {:2.4f}'.format(total_corrects / 60000))\n",
    "\n",
    "    sess.run(test_init)\n",
    "    total_corrects = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            corrects_val = sess.run(num_correct_preds)\n",
    "            total_corrects += corrects_val\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print('Test accuracy = {:2.4f}'.format(total_corrects / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2a_poedgfpI"
   },
   "source": [
    "# TF High Level APIs\n",
    "TensorFlow provides high level APIs to define and execute neural network more easily. In this session, we will take a look at two of them: Keras and Eager execution.\n",
    "\n",
    "## 1. Keras (tf.keras)\n",
    "Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production, with three key advantages:\n",
    "\n",
    "- **User friendly**: Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
    "- **Modular and composable**: Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
    "- **Easy to extend**: Write custom building blocks to express new ideas for research. Create new layers, loss functions, and develop state-of-the-art models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gR4oMDv4siyO"
   },
   "source": [
    "### Defining a model\n",
    "Keras API is accessible in the `tf.keras` namespace. Let's take a look how we can define a model using Keras API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2718,
     "status": "ok",
     "timestamp": 1571380248813,
     "user": {
      "displayName": "Gyeong-In Yu",
      "photoUrl": "",
      "userId": "06641939619571661692"
     },
     "user_tz": -540
    },
    "id": "BpJTfmFwZFAw",
    "outputId": "6504f307-0b5a-40ee-e844-19023a841a8b"
   },
   "outputs": [],
   "source": [
    "#keras는 최신 텐서플로 api, data set api와 인터렉션이 편해짐\n",
    "#확장성쉽고, 사용도 편하고..\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Let's build a stack of *sequential* layers, which is\n",
    "# the most common form of neural network graphs.\n",
    "model = tf.keras.Sequential()\n",
    "#여러개의 모델 빈껍데기 생성\n",
    "\n",
    "# Adds a reshaping layer that transforms (28, 28, 1) to (784,)\n",
    "model.add(layers.Reshape((784,), input_shape=(28, 28, 1)))\n",
    "#원하는 레이어 생성 28x28x1을 781로 바꿈\n",
    "\n",
    "# Adds a dense layer with 128 units to the model\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "# 784짜리 유닛에 128짜리 유닛으로 바꾸는 dense activation 씀\n",
    "\n",
    "\n",
    "# Adds another layer, which has L2 regularization applied to the kernel matrix\n",
    "model.add(layers.Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "#커널에 L2 regul 사용 너무 복잡해지지 않도록 쓰는 방법\n",
    "\n",
    "\n",
    "# Adds a dense layer with 10 output units\n",
    "model.add(layers.Dense(units=10, activation='linear'))\n",
    "#마지막으로 10개의 클래스로 학습해야하니 linear한 dense layer추가 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4SmnPgAbVAS"
   },
   "source": [
    "If you visit https://www.tensorflow.org/api_docs/python/tf/keras/layers, you can find the supported layers, for example, Conv2D, BatchNormalization, LSTM, MaxPool, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJq7I5kOc1H-"
   },
   "source": [
    "### Setting up training\n",
    "After the model is constructed, `compile` method configures how to learn the model, which allows us to specify the following:\n",
    "* `optimizer`: This field specifies which optimizer to use. We can pass an optimizer instance (e.g., `tf.train.AdamOptimizer`, `tf.train.RMSPropOptimizer`), which are defined in  `tf.train` module.\n",
    "* `loss`: The function to minimize during optimization. Common choices include `mean square error (mse)`, `[categorical|binary]_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
    "* `metrics`: Used to monitor training. We can put string names or callables defined in `tf.keras.metrics` module (e.g. `'accuracy'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ocskyx96c0UY"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "#metircs에 accuracy면 accuracy가 얼마인지 보여준다.\n",
    "#모델이 전부 준비가 된것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSo7qrwZlOrl"
   },
   "source": [
    "### Training a model\n",
    "We can train the model using the `fit` method and then the model is \"fit\" to the training data. We can specify the training data to use (`images_train` and `labels_train`), how many epochs we will run (`epochs`), and how many items to be processed in a batch (`batch_size`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39544,
     "status": "ok",
     "timestamp": 1571380621301,
     "user": {
      "displayName": "Gyeong-In Yu",
      "photoUrl": "",
      "userId": "06641939619571661692"
     },
     "user_tz": -540
    },
    "id": "nPOV-4VXk53s",
    "outputId": "f2190ce6-7313-4f10-886a-f52e7121bac0"
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
    "#트레이닝 폭 10번"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymPOEP3BlivE"
   },
   "source": [
    "### Evaluating the model\n",
    "Finally, we evaluate the trained model using test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1571380762906,
     "user": {
      "displayName": "Gyeong-In Yu",
      "photoUrl": "",
      "userId": "06641939619571661692"
     },
     "user_tz": -540
    },
    "id": "yV5w-V99l0Di",
    "outputId": "e27204fa-8cdb-4e36-a1de-12f8d15849ad"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4ORwtammNNb"
   },
   "source": [
    "### Quiz 1.\n",
    "First, define a multi-layer model following the CNN model defined above using `tf.layers` API.\n",
    "The model comprises 3 convolutional layers, 3 max pooling layers, and 1 dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhKpYAgszdkI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "############# Write here. #############\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(...)\n",
    "\n",
    "\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmnL8eeL613b"
   },
   "source": [
    "Using the model and `(image, labels)` above, let's train the model using the following configuration:\n",
    "* optimizer: `tf.train.AdamOptimizer`\n",
    "* learning rate: 0.001\n",
    "* loss: `SparseCategoricalCrossentropy`\n",
    "* metrics: `accuracy`\n",
    "* batch size: 128\n",
    "* epochs: 10\n",
    "\n",
    "Then, change the model to employ l2 regualrization loss on weights using coefficient `1e-4`.\n",
    "Let's check whether the regualrization improves the accuracy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0tNzWLWz0bj"
   },
   "outputs": [],
   "source": [
    "############# Write here. #############\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
    "#######################################\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLHgqqrmW2nJ"
   },
   "source": [
    "## 2. Eager execution\n",
    "\n",
    "Eager execution is a flexible machine learning platform for research and experimentation, providing:\n",
    "\n",
    "* **An intuitive interface** Structure your code naturally and use Python data structures. Quickly iterate on small models and small data.\n",
    "* **Easier debugging** Call ops directly to inspect running models and test changes. Use standard Python debugging tools for immediate error reporting.\n",
    "* **Natural control flow** Use Python control flow instead of graph control flow, simplifying the specification of dynamic models.\n",
    "\n",
    "Eager execution supports most TensorFlow operations and GPU acceleration. For a collection of examples running in eager execution, see: tensorflow/contrib/eager/python/examples.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNfqm-LqvU8y"
   },
   "source": [
    "\n",
    "### Setup\n",
    "\n",
    "To start eager execution, add `tf.enable_eager_execution()`\n",
    " to the **beginning** of the program or console session. In the jupyter (or colab) environment, you need to restart the runtime if the session has executed any command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sp52QHc2vj0S"
   },
   "outputs": [],
   "source": [
    "#그래프를 정의하고 차후에 수행하는 방식 과 다르게 파이선 코드레벨에서 적용되어 바로 진행되는 방식. 직관적\n",
    "#파이선에 기본적으로 있는 pdb를 바로 쓸수있음 디버깅등\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZpmQwNYvRFI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks whether the eager mode is used (True if enabled)\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U0vlTsmKxSgu"
   },
   "source": [
    "Unlike in the graph mode, all operations (e.g., constant, matrix multiplication) are returned directly. Recall that the operators are not executed until `Session.run()` and thus the values are not available even though we run statement in Python level.\n",
    "\n",
    "### Constants\n",
    "Instead, in the eager execution, the values are returned immediately. Let's start with constants that we defined at the previous sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CchaD-LnF1W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 2]\n",
      " [1 3]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#그래프를 수행하는 sess run이 없어짐\n",
    "#name은 의미 없음\n",
    "# constant of 1d tensor, or a vector\n",
    "a = tf.constant([2,2], name = 'vector')\n",
    "\n",
    "# constant of 2x2 tensor, or a matrix\n",
    "b = tf.constant([[0,2], [1,3]], name = 'matrix')\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# See what happens if you uncomment the last line\n",
    "# print(a.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ck-CzsbjUP5c"
   },
   "source": [
    "We can see the results are printed. Obviously, the `name` field is not useful since we can now access the values in python code, so uncommenting the last line raises an error in `Tensor.name`.\n",
    "\n",
    "As you might notice, this way is simpler and more intuitive than in the graph mode, where the value can be retrieved only when `session.run()` is called as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBLi8p3yV2cQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vector:0\", shape=(2,), dtype=int32)\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "# In the graph mode, print(aa) prints only the metadata of aa\n",
    "# aa라는 것에 그래프를 정의할 때 eager에서는 [2,2]라는게 값을 갖고 있는게 차이점\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    aa = tf.constant([2,2], name = 'vector')\n",
    "print(aa)\n",
    "  \n",
    "# The value of the aa can be obtained through sess.run(aa)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    print(sess.run(aa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZL3Sz4aGYpQg"
   },
   "source": [
    "### Math Ops\n",
    "Eager execution also allows the mathmatical operations to be computed immediately. Let's take the same examples that we saw with the graph mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVLXaK3UXFqe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1]\n",
      " [0 1]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "div = tf.div(b, a)\n",
    "print(div)\n",
    "# sess.run할필요 없이 바로 수행가능\n",
    "# See what happens if you uncomment the last line\n",
    "# print(div.op) #에러뜸 operation없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfLYTXCAZIF4"
   },
   "source": [
    "Even better, TF eager execution supports operator overloading and numpy operations. See how the computation becomes easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nXofidfZDoj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  1. ]\n",
      " [0.5 1.5]], shape=(2, 2), dtype=float64)\n",
      "[[0.  1. ]\n",
      " [0.5 1.5]]\n"
     ]
    }
   ],
   "source": [
    "# Operator overloading\n",
    "print(b/a)\n",
    "\n",
    "# Numpy integration\n",
    "import numpy as np\n",
    "print(np.divide(b, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-cE5TvAWgxr"
   },
   "source": [
    "### Quiz 2.\n",
    "Define three 2x2 matrices (A, B, C) with the following values, and print the value of A x B + C (use eager execution)\n",
    "* A: [[3, 4], [2, 1]]\n",
    "* B: [[1,2], [1,2]]\n",
    "* C: [[-1,1],[4,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzZHCPpj9RwG"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/yunseonglee/venv-bdc/lib/python3.5/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'as_datatype_enum'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a13fa2b3f3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m########## Write here. ##########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yunseonglee/venv-bdc/lib/python3.5/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant_v1\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \"\"\"\n\u001b[1;32m    160\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=verify_shape,\n\u001b[0;32m--> 161\u001b[0;31m                         allow_broadcast=False)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yunseonglee/venv-bdc/lib/python3.5/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yunseonglee/venv-bdc/lib/python3.5/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yunseonglee/venv-bdc/lib/python3.5/site-packages/tensorflow_core/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ANY_TO_TF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "########## Write here. ##########\n",
    "a = tf.constant([3,4], [2,1])\n",
    "b = tf.constant([1,2], [1,2])\n",
    "c = tf.constant([-1,1], [4,1])\n",
    "prin(axb+c)\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8lKERiI47yRI"
   },
   "source": [
    "### Dynamic control flow\n",
    "\n",
    "A major benefit of eager execution is that all the functionality of the host language is available while your model is executing. So, for example, it is easy to write fizzbuzz game where any number divisible by three is replaced with the word \"fizz\", and any number divisible by five is replaced with the word \"buzz\" (similar to the 3-6-9 game)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6VNGtHn0vIt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n",
      "16\n",
      "17\n",
      "Fizz\n",
      "19\n",
      "Buzz\n"
     ]
    }
   ],
   "source": [
    "# Native python code\n",
    "def fizzbuzz(max_num):\n",
    "    counter = 0\n",
    "    for num in range(1, max_num+1):\n",
    "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "            print('FizzBuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num)\n",
    "        counter += 1\n",
    "    \n",
    "fizzbuzz(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4d4wnik07wk"
   },
   "source": [
    "In eager execution, we need to add minor changes in a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4De2BYMb7tPw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n",
      "16\n",
      "17\n",
      "Fizz\n",
      "19\n",
      "Buzz\n"
     ]
    }
   ],
   "source": [
    "def fizzbuzz_eager(max_num):\n",
    "    counter = tf.constant(0) # counter = 0\n",
    "    max_num = tf.convert_to_tensor(max_num) #\n",
    "    for num in range(1, max_num.numpy() + 1): #\n",
    "        num = tf.constant(num) # \n",
    "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "            print('FizzBuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num.numpy()) # print(num)\n",
    "        counter += 1\n",
    "    \n",
    "fizzbuzz_eager(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASf7wXXOqoFU"
   },
   "source": [
    "Implementing the same thing using TensorFlow graph mode: [Tensorflow FizzBuzz Revisited (Ricky Han blog)](https://rickyhan.com/jekyll/update/2018/02/16/tensorflow-fizzbuzz-revisited.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yb4AqjBIsHWb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'1' b'2' b'Fizz' b'4' b'Buzz' b'Fizz' b'7' b'8' b'Fizz' b'Buzz' b'11'\n",
      " b'Fizz' b'13' b'14' b'FizzBuzz' b'16' b'17' b'Fizz' b'19' b'Buzz' b'Fizz'\n",
      " b'22' b'23' b'Fizz' b'Buzz' b'26' b'Fizz' b'28' b'29' b'FizzBuzz' b'31'\n",
      " b'32' b'Fizz' b'34' b'Buzz' b'Fizz' b'37' b'38' b'Fizz' b'Buzz' b'41'\n",
      " b'Fizz' b'43' b'44' b'FizzBuzz' b'46' b'47' b'Fizz' b'49' b'Buzz' b'Fizz'\n",
      " b'52' b'53' b'Fizz' b'Buzz' b'56' b'Fizz' b'58' b'59' b'FizzBuzz' b'61'\n",
      " b'62' b'Fizz' b'64' b'Buzz' b'Fizz' b'67' b'68' b'Fizz' b'Buzz' b'71'\n",
      " b'Fizz' b'73' b'74' b'FizzBuzz' b'76' b'77' b'Fizz' b'79' b'Buzz' b'Fizz'\n",
      " b'82' b'83' b'Fizz' b'Buzz' b'86' b'Fizz' b'88' b'89' b'FizzBuzz' b'91'\n",
      " b'92' b'Fizz' b'94' b'Buzz' b'Fizz' b'97' b'98' b'Fizz' b'Buzz']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def fizzbuzz_graph(max_num):\n",
    "    # Define variable and while_loop\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        arr = tf.Variable([str(i) for i in range(1, max_num+1)])\n",
    "        # nasty tf.while_loop and tf.cond ops\n",
    "        while_op = tf.while_loop(\n",
    "            (lambda i, _: tf.less(i, max_num+1)), \n",
    "            (lambda i, _: (tf.add(i,1), tf.cond(\n",
    "                tf.logical_and(tf.equal(tf.mod(i, 3), 0), tf.equal(tf.mod(i, 5), 0)),\n",
    "                (lambda : tf.assign(arr[(i - 1)], 'FizzBuzz')),\n",
    "                (lambda : tf.cond(tf.equal(tf.mod(i, 3), 0),\n",
    "                    (lambda : tf.assign(arr[(i - 1)], 'Fizz')),\n",
    "                    (lambda : tf.cond(tf.equal(tf.mod(i, 5), 0),\n",
    "                        (lambda : tf.assign(arr[(i - 1)], 'Buzz')),\n",
    "                        (lambda : arr)))))))),\n",
    "            [1, arr])\n",
    "\n",
    "    # Call Session.run()\n",
    "    with tf.Session(graph = graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        idx, array = sess.run(while_op)\n",
    "        print(array)\n",
    "\n",
    "\n",
    "fizzbuzz_graph(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNwIJ58cvy2n"
   },
   "source": [
    "### Eager training\n",
    "\n",
    "Automatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks. During eager execution, use `tf.GradientTape` to trace operations for computing gradients later.\n",
    "\n",
    "`tf.GradientTape` is an opt-in feature to provide maximal performance when not tracing. Since different operations can occur during each call, all forward-pass operations get recorded to a \"tape\". To compute the gradient, play the tape backwards and then discard. A particular `tf.GradientTape` can only compute gradients once; subsequent calls throw a runtime error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "embmV_cFv4Bq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2. 4.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#eager로 execution할수있는데, tarin은 backpropagation으로 gradient로 계산해야됨.\n",
    "#tensor에서는 earger로 forwoard로 다 기록이됨. 꺼꾸로 가면서 그레디언트 계산\n",
    "w = tf.Variable([[1.0, 2.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w * w #relu등이 여기서 수행됨\n",
    "\n",
    "grad = tape.gradient(loss, w) #처음 뭐에 gradint를 뽑을거냐.\n",
    "print(grad)  # => tf.Tensor([[2. 4.]], shape=(1, 2), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqWzzFUO79nx"
   },
   "source": [
    "### Model Subclassing\n",
    "We can build a fully-customizable model by subclassing [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) and defining your own forward pass. Layers are created in the `__init__` method and they are set as attributes of the class instance. The forward pass is defined in the `call` method. Model subclassing is particularly useful when eager execution is enabled since you don't have to worry about keeping track of your variables. You can always access them by `model.trainable_variables`.\n",
    "\n",
    "Below is an example of a linear regression model to be defined as a subclass of `tf.keras.Model`, and then be trained using loss and gradient function, which is defined imperatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 2000\n",
    "toy_inputs = tf.random_normal([NUM_EXAMPLES, 1])\n",
    "noise = tf.random_normal([NUM_EXAMPLES, 1])\n",
    "toy_outputs = toy_inputs * 2 - 1 + noise * 1/4\n",
    "\n",
    "#linear regression모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 8.843\n",
      "Trainable variables: [<tf.Variable 'toy_model/dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-0.84334433]], dtype=float32)>, <tf.Variable 'toy_model/dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class ToyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        \"\"\"Define layers\"\"\"\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.dense = tf.keras.layers.Dense(units=1) #tf. variable들을 정의\n",
    "\n",
    "    def call(self, input):\n",
    "        \"\"\"Define forward pass.\"\"\"\n",
    "        result = self.dense(input)        \n",
    "        return result #어떤 연산이 적용되었는지. cnn은 class cnn tf.keras모델을 부모르 가져오고 self.conv1, conv2, conv3정의하고 fully conected layer정의\n",
    "    #self.max1, max2 다음 layer 계산할수있도록 적용\n",
    "    #여기는 dense layer 1개임\n",
    "\n",
    "# The loss function to be optimized (MSE loss)\n",
    "def loss(model, inputs, targets):\n",
    "    error = model(inputs) - targets\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "model = ToyModel()\n",
    "print(\"Initial loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
    "print(\"Trainable variables:\", model.trainable_variables) #어떤 varialbe이 tariner variable접근\n",
    "#크기하나짜리 커널 shape1x1 등ㅇ이 모델에 존재하는 것을 확인할수있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZ3w_EmG7shn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 000: 0.065\n",
      "Loss at step 020: 0.065\n",
      "Loss at step 040: 0.065\n",
      "Loss at step 060: 0.065\n",
      "Loss at step 080: 0.065\n",
      "Loss at step 100: 0.065\n",
      "Loss at step 120: 0.065\n",
      "Loss at step 140: 0.065\n",
      "Loss at step 160: 0.065\n",
      "Loss at step 180: 0.065\n",
      "Loss at step 200: 0.065\n",
      "Loss at step 220: 0.065\n",
      "Loss at step 240: 0.065\n",
      "Loss at step 260: 0.065\n",
      "Loss at step 280: 0.065\n",
      "Final loss: 0.065\n",
      "Trainable variables: [<tf.Variable 'toy_model/dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9967932]], dtype=float32)>, <tf.Variable 'toy_model/dense/bias:0' shape=(1,) dtype=float32, numpy=array([-0.9994885], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in range(300):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, toy_inputs, toy_outputs)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables) #loss funcion이 그레디언트를 desnce layer의 커널과 바이어스로 그레디언트\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables), \n",
    "                              global_step=tf.train.get_or_create_global_step()) #위에 그레디언트로 optimizer ㄱㄱ, 기존은 sess.run으로 수행\n",
    "    if i % 20 == 0:\n",
    "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, toy_inputs, toy_outputs)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
    "print(\"Trainable variables:\", model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8MEnHhAvskB"
   },
   "source": [
    "It's not required to set an input shape for the `tf.keras.Model` class since the parameters are set the first time input is passed to the layer.\n",
    "\n",
    "tf.keras.layers classes create and contain their own model variables that are tied to the lifetime of their layer objects. To share layer variables, share their objects.\n",
    "\n",
    "Below examples shows a new model that relies on the previous toy model. We are going to employ an additional bias to fit a slightly different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 9.065\n",
      "Trainable variables: [<tf.Variable 'toy_model/dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9967932]], dtype=float32)>, <tf.Variable 'toy_model/dense/bias:0' shape=(1,) dtype=float32, numpy=array([-0.9994885], dtype=float32)>, <tf.Variable 'another_bias:0' shape=() dtype=float32, numpy=0.0>]\n"
     ]
    }
   ],
   "source": [
    "#이 모델을 가져와서 데이타셋을 다르게 쓰는.. 모든 값이 +3이됨/ -1에 +3이라 다른 파라미터 모델필요\n",
    "#바이어스 추가 한다음에 그것만 학습\n",
    "toy_outputs_2 = toy_outputs + 3\n",
    "\n",
    "class ToyModel2(tf.keras.Model):\n",
    "    def __init__(self, toy_model): #아까만든 토이모델\n",
    "        \"\"\"Define layers\"\"\"\n",
    "        super(ToyModel2, self).__init__()\n",
    "        self.toy_model = toy_model\n",
    "        self.b = tf.Variable(0., name='another_bias') #0으로 초기화된 다른 바이어스로 적용\n",
    "\n",
    "    def call(self, input):\n",
    "        \"\"\"Define forward pass.\"\"\"\n",
    "        result = self.toy_model(input)        \n",
    "        return result + self.b #바이어스 추가\n",
    "\n",
    "\n",
    "model2 = ToyModel2(model) #초기값 받는다\n",
    "print(\"Initial loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2))) # 3x3이라서 9의 에러를 볼수있음\n",
    "print(\"Trainable variables:\", model2.trainable_variables)\n",
    "\n",
    "\n",
    "#Trainable variables: [<tf.Variable 'toy_model/dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9967932]], dtype=float32)>, \n",
    "#<tf.Variable 'toy_model/dense/bias:0' shape=(1,) dtype=float32, numpy=array([-0.9994885], dtype=float32)>, \n",
    "#<tf.Variable 'another_bias:0' shape=() dtype=float32, 초기화 numpy=0.0>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only optimizing the additional bias. The weight and bias of toy_model_1 does not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhNlE5mTw7bX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 000: 8.709\n",
      "Loss at step 020: 3.917\n",
      "Loss at step 040: 1.782\n",
      "Loss at step 060: 0.830\n",
      "Loss at step 080: 0.406\n",
      "Loss at step 100: 0.217\n",
      "Loss at step 120: 0.133\n",
      "Loss at step 140: 0.095\n",
      "Loss at step 160: 0.078\n",
      "Loss at step 180: 0.071\n",
      "Loss at step 200: 0.068\n",
      "Loss at step 220: 0.066\n",
      "Loss at step 240: 0.065\n",
      "Loss at step 260: 0.065\n",
      "Loss at step 280: 0.065\n",
      "Final loss: 0.065\n",
      "Trainable variables: [<tf.Variable 'toy_model/dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9967932]], dtype=float32)>, <tf.Variable 'toy_model/dense/bias:0' shape=(1,) dtype=float32, numpy=array([-0.9994885], dtype=float32)>, <tf.Variable 'another_bias:0' shape=() dtype=float32, numpy=2.9930015>]\n"
     ]
    }
   ],
   "source": [
    "# Training loop. anothger bias만 학습\n",
    "for i in range(300):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model2, toy_inputs, toy_outputs_2)\n",
    "    grads = tape.gradient(loss_value, [model2.b]) # gradient w.r.t. `model2.b`, not `model2.trainable_variables`\n",
    "    optimizer.apply_gradients(zip(grads, [model2.b]), # optimize only `model2.b`\n",
    "                              global_step=tf.train.get_or_create_global_step())\n",
    "    if i % 20 == 0:\n",
    "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model2, toy_inputs, toy_outputs_2)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n",
    "print(\"Trainable variables:\", model2.trainable_variables)\n",
    "\n",
    "# <tf.Variable 'another_bias:0' shape=() dtype=float32, numpy=2.9930015> +3으로 추가하여서 학습됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOowIsLDs7J_"
   },
   "source": [
    "## Wrap-up\n",
    "\n",
    "So far, we have learned how we can use two types of high-level APIs: Keras and eager execution. For more information about Keras and Eager execution, you can visit https://www.tensorflow.org/guide/keras and https://www.tensorflow.org/guide/eager, respectively (and many other blog posts as well!)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF High-level APIs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Cloud for Big Data",
   "language": "python",
   "name": "bdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
