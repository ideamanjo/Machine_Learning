{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1,2,3,4,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_excel(\"./train_rev5.xlsx\",index_col=0,parse_dates=[0])\n",
    "df2 = pd.read_excel(\"./test_rev5.xlsx\",index_col=0,parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique index 바꾸기\n",
    "\n",
    "df1['country'] = df1['country'].map(df1['country'].value_counts())\n",
    "#df1['description'] = df1['description'].map(df1['description'].value_counts())\n",
    "df1['designation'] = df1['designation'].map(df1['designation'].value_counts())\n",
    "df1['province'] = df1['province'].map(df1['province'].value_counts())\n",
    "df1['region_1'] = df1['region_1'].map(df1['region_1'].value_counts())\n",
    "df1['region_2'] = df1['region_2'].map(df1['region_2'].value_counts())\n",
    "df1['taster_name'] = df1['taster_name'].map(df1['taster_name'].value_counts())\n",
    "#df1['taster_twitter_handle'] = df1['taster_twitter_handle'].map(df1['taster_twitter_handle'].value_counts())\n",
    "df1['title'] = df1['title'].map(df1['title'].value_counts())\n",
    "df1['variety'] = df1['variety'].map(df1['variety'].value_counts())\n",
    "df1['winery'] = df1['winery'].map(df1['winery'].value_counts())\n",
    "df1['vintage'] = df1['vintage'].map(df1['vintage'].value_counts())\n",
    "df1['continent'] = df1['continent'].map(df1['continent'].value_counts())\n",
    "df1['description_len'] = df1['description'].astype(str).map(len)\n",
    "\n",
    "\n",
    "\n",
    "df2['country'] = df2['country'].map(df2['country'].value_counts())\n",
    "#df2['description'] = df2['description'].map(df2['description'].value_counts())\n",
    "df2['designation'] = df2['designation'].map(df2['designation'].value_counts())\n",
    "df2['province'] = df2['province'].map(df2['province'].value_counts())\n",
    "df2['region_1'] = df2['region_1'].map(df2['region_1'].value_counts())\n",
    "df2['region_2'] = df2['region_2'].map(df2['region_2'].value_counts())\n",
    "df2['taster_name'] = df2['taster_name'].map(df2['taster_name'].value_counts())\n",
    "#df2['taster_twitter_handle'] = df2['taster_twitter_handle'].map(df2['taster_twitter_handle'].value_counts())\n",
    "df2['title'] = df2['title'].map(df2['title'].value_counts())\n",
    "df2['variety'] = df2['variety'].map(df2['variety'].value_counts())\n",
    "df2['winery'] = df2['winery'].map(df2['winery'].value_counts())\n",
    "df2['vintage'] = df2['vintage'].map(df2['vintage'].value_counts())\n",
    "df2['continent'] = df2['continent'].map(df2['continent'].value_counts())\n",
    "df2['description_len'] = df2['description'].astype(str).map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1.points  \n",
    "X = df1[['price','vintage','vintage_','price_modify','grade_germany', 'grade_italy','grade_spain','grade_france','grade_italy','grade_spain','grade_france','description_len','designation_len_modify','Rating_Avg','pre_points']]\n",
    "X_test_set = df2[['price','vintage','vintage_','price_modify','grade_germany', 'grade_italy','grade_spain','grade_france','grade_italy','grade_spain','grade_france','description_len','designation_len_modify','Rating_Avg','pre_points']]\n",
    "\n",
    "#X = df1[['country','price','province','region_1', 'region_2', 'taster_name', 'title','variety','winery','vintage','vintage_','taster_name_q2_modify','price_modify','province_modify','continent',  'grade_germany', 'grade_italy','grade_spain','grade_france','grade_italy','grade_spain','grade_france','description_len','designation','Rating_Avg','pre_points']]\n",
    "#X_test_set = df2[['country','price', 'province','region_1', 'region_2', 'taster_name', 'title','variety','winery','vintage','vintage_','taster_name_q2_modify','price_modify','province_modify','continent',  'grade_germany', 'grade_italy','grade_spain','grade_france','grade_italy','grade_spain','grade_france','description_len','designation','Rating_Avg','pre_points']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = X.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "X = pd.DataFrame(x_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import AdaBoostRegressor as ADA\n",
    "from sklearn.ensemble import BaggingRegressor as BAG\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.linear_model import RANSACRegressor as RAN\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor as PAR\n",
    "from sklearn.linear_model import SGDRegressor as SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.layers import LSTM \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "import keras.backend as K \n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:06<01:12,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.30454951366809446\n",
      "first derivative:  0.012111457339826437\n",
      "featness:  8.255222223997185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [00:07<01:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.6005922402790791\n",
      "first derivative:  0.5884807829392527\n",
      "featness:  8.22356155601358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:09<01:07,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.7505963035163115\n",
      "first derivative:  0.1621155205770588\n",
      "featness:  8.579453265151303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [00:10<01:06,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.3659109164464711\n",
      "first derivative:  0.5280264370235299\n",
      "featness:  9.27961443006064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:12<01:07,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.5000569529342087\n",
      "first derivative:  0.027969484089321206\n",
      "featness:  8.635392233329945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:13<01:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.19338119468000148\n",
      "first derivative:  0.16541171059068027\n",
      "featness:  8.94879100887928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [00:15<01:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.04993901736907791\n",
      "first derivative:  0.21535072795975818\n",
      "featness:  8.204690777410429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:16<00:57,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.204923418202414\n",
      "first derivative:  0.010427309757344183\n",
      "featness:  8.927936389364591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:18<00:55,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.1669598663890497\n",
      "first derivative:  0.1565325566317055\n",
      "featness:  8.51775589067384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [00:19<00:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.43344393247177315\n",
      "first derivative:  0.27691137584006764\n",
      "featness:  8.374113637684456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [00:20<00:51,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.21729989284650308\n",
      "first derivative:  0.05961148299356456\n",
      "featness:  8.39853292468671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:22<00:48,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.17363919674924677\n",
      "first derivative:  0.11402771375568221\n",
      "featness:  8.60216906519582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:23<00:46,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.49405720384226104\n",
      "first derivative:  0.6080849175979433\n",
      "featness:  9.614702759882597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [00:24<00:45,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.34958300100130657\n",
      "first derivative:  0.2585019165966367\n",
      "featness:  9.119172898389094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [00:26<00:43,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.05042750578602462\n",
      "first derivative:  0.20807441081061206\n",
      "featness:  10.030851581503821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [00:27<00:41,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.13866315903870863\n",
      "first derivative:  0.06941125177190344\n",
      "featness:  9.2579954019329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [00:29<00:41,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -1.0262234749392771\n",
      "first derivative:  0.9568122231673737\n",
      "featness:  8.117227135169074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [00:30<00:41,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.7475657122968036\n",
      "first derivative:  0.2092465108705701\n",
      "featness:  8.83950238019176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [00:32<00:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.8078226995446602\n",
      "first derivative:  0.5985761886740901\n",
      "featness:  9.314379512517254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [00:33<00:40,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.5493573155693703\n",
      "first derivative:  0.04921887310471984\n",
      "featness:  8.9379401264012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [00:35<00:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.08747102409501739\n",
      "first derivative:  0.03825215099029755\n",
      "featness:  9.237875210536659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [00:36<00:38,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.021336568986892956\n",
      "first derivative:  0.05958871997719051\n",
      "featness:  8.818762686446819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [00:38<00:35,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.14724503670608247\n",
      "first derivative:  0.20683375668327297\n",
      "featness:  8.824207697170113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [00:39<00:33,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.3711907703353967\n",
      "first derivative:  0.16435701365212374\n",
      "featness:  9.147476713751066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [00:41<00:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.37520788627434776\n",
      "first derivative:  0.21085087262222402\n",
      "featness:  8.402505951925665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [00:42<00:30,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.09403047503699558\n",
      "first derivative:  0.3048813476592196\n",
      "featness:  8.537714018432627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [00:43<00:28,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.3378856457409194\n",
      "first derivative:  0.0330042980816998\n",
      "featness:  8.468514548089065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [00:45<00:26,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.252044099524956\n",
      "first derivative:  0.2850483976066558\n",
      "featness:  9.107810813645939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [00:46<00:24,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.05343790380900515\n",
      "first derivative:  0.33848630141566094\n",
      "featness:  9.145487150920387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [00:48<00:23,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.6119388059505297\n",
      "first derivative:  0.2734525045348688\n",
      "featness:  8.560905804576201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [00:49<00:22,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.0032390381910119004\n",
      "first derivative:  0.2766915427258807\n",
      "featness:  8.592104065468625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [00:50<00:20,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.28530940420614215\n",
      "first derivative:  0.008617861480261446\n",
      "featness:  8.578141527536724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [00:52<00:19,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.01812749720765172\n",
      "first derivative:  0.026745358687913168\n",
      "featness:  8.645594782844451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [00:53<00:17,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.028177235098574727\n",
      "first derivative:  0.054922593786487894\n",
      "featness:  8.6879867151097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [00:54<00:16,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.1521097176329933\n",
      "first derivative:  0.09718712384650541\n",
      "featness:  8.45122053515144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [00:56<00:14,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.47727077263710793\n",
      "first derivative:  0.3800836487906025\n",
      "featness:  9.448154012690905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [00:57<00:14,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.10332340882404978\n",
      "first derivative:  0.4834070576146523\n",
      "featness:  9.418034650380745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [00:59<00:12,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -1.0927062136752124\n",
      "first derivative:  0.6092991560605601\n",
      "featness:  8.229555700569785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [01:00<00:11,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.21129020713935098\n",
      "first derivative:  0.3980089489212091\n",
      "featness:  8.622016752538327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [01:01<00:09,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.44201548649836475\n",
      "first derivative:  0.04400653757715567\n",
      "featness:  8.317568775724096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [01:03<00:08,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.5230356950621324\n",
      "first derivative:  0.5670422326392881\n",
      "featness:  9.756101217816903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [01:04<00:07,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.23730896066630525\n",
      "first derivative:  0.32973327197298286\n",
      "featness:  8.977035319670062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [01:06<00:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.46335386318969896\n",
      "first derivative:  0.1336205912167161\n",
      "featness:  9.488860035383471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [01:07<00:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.0025130174522240978\n",
      "first derivative:  0.1361336086689402\n",
      "featness:  8.704768102332181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [01:09<00:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.046751664599439025\n",
      "first derivative:  0.08938194406950117\n",
      "featness:  9.310096147244469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [01:10<00:01,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.26440503684901273\n",
      "first derivative:  0.17502309277951156\n",
      "featness:  9.054814287891205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:12<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.7543798251424514\n",
      "first derivative:  0.5793567323629398\n",
      "featness:  8.151382682518589\n",
      "2.849074785815401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ensemble_search:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test,\n",
    "                 size_pop=20, epochs=5, verbose=True):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.size_pop = size_pop\n",
    "        self.epochs = epochs\n",
    "        self.fitness_array_ = np.array([])\n",
    "        self.best_of_all_ = None\n",
    "        self.verbose_ = verbose\n",
    "\n",
    "    def gen_population(self):\n",
    "        \n",
    "        population = [[]]*self.size_pop\n",
    "        \n",
    "        for i in range(self.size_pop):\n",
    "            \n",
    "            qt_regressor = np.random.randint(2,9)\n",
    "            lista_LR = ['LR',LR(), {}]\n",
    "            \n",
    "            lista_RFR = ['RFR',RFR(), \n",
    "                         {'n_estimators':np.random.randint(1,100),\n",
    "                          'max_depth':np.random.randint(1,20),\n",
    "                          'min_samples_split':np.random.randint(2,5),      \n",
    "                          'min_samples_leaf':np.random.randint(2,10),   \n",
    "                          'min_weight_fraction_leaf':np.random.rand(1)[0]/2}]\n",
    "            \n",
    "            lista_SVR = ['SVR',SVR(),\n",
    "                         {'kernel':random.choice(['linear','rbf','poly','sigmoid']),     \n",
    "                          'epsilon':np.random.rand(1)[0]/4,\n",
    "                          'C':random.choice([1,10,100,1000]),'gamma':'auto'}]\n",
    "            \n",
    "            lista_ADA = ['ADA',ADA(), \n",
    "                         {'n_estimators':np.random.randint(1,50)}]\n",
    "            \n",
    "            lista_BAG = ['BAG',BAG(), \n",
    "                         {'n_estimators':np.random.randint(1,50),'max_samples':np.random.randint(1,20)}]\n",
    "            \n",
    "            lista_GBR = ['GBR',GBR(), \n",
    "                         {'n_estimators':np.random.randint(1,100),'max_depth':np.random.randint(1,20),        \n",
    "                          'min_samples_split':np.random.randint(2,5),      \n",
    "                          'min_samples_leaf':np.random.randint(2,10),     \n",
    "                          'min_weight_fraction_leaf':np.random.rand(1)[0]/2}]\n",
    "            \n",
    "            lista_RAN = ['RAN',RAN(), {}]\n",
    "            \n",
    "            lista_PAR = ['PAR',PAR(), \n",
    "                         {'C': np.random.randint(1,10), 'early_stopping':True,        \n",
    "                          'n_iter_no_change':np.random.randint(1,10)}]\n",
    "            \n",
    "            lista_SGD = ['SGD',SGD(), {}]\n",
    "            \n",
    "            lista_regressors = [lista_LR,lista_RFR,lista_SVR,lista_ADA,lista_BAG,\n",
    "                                lista_GBR,lista_RAN,lista_PAR,lista_SGD]\n",
    "            \n",
    "            random.shuffle(lista_regressors)\n",
    "            \n",
    "            lista_regressors = lista_regressors[0:qt_regressor]\n",
    "            \n",
    "            for j in range(len(lista_regressors)):\n",
    "                lista_regressors[j][1] = lista_regressors[j][1].set_params(**lista_regressors[j][2])\n",
    "\n",
    "            population[i] = [qt_regressor, lista_regressors, 'voting_regressor', np.inf]\n",
    "            \n",
    "        return population\n",
    "\n",
    "    def set_fitness(self, population):\n",
    "        for i in range(len(population)):\n",
    "            \n",
    "            lista_tuplas_VR = []\n",
    "            nomes = []\n",
    "            for indv in population[i][1]:\n",
    "                \n",
    "                while indv[0] in nomes: #adionar X se o nome já estiver dentro\n",
    "                    indv[0] = indv[0]+'X'\n",
    "                nomes.append(indv[0])\n",
    "                \n",
    "                lista_tuplas_VR.append((indv[0],indv[1])) #aqui vai pegando cada regressor do indivíduo (lista de regressores),\n",
    "                                                          #que é formado pelo nome do regressor e o objeto.\n",
    "                \n",
    "            Voting_regressor = VotingRegressor(lista_tuplas_VR)\n",
    "            Voting_regressor.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            mae_vr = mae(Voting_regressor.predict(self.X_test), self.y_test)\n",
    "            population[i][-1] = mae_vr\n",
    "            population[i][-2] = Voting_regressor\n",
    "            \n",
    "        return population\n",
    "    \n",
    "    def next_population(self, population):\n",
    "        \n",
    "        for i in range(1, int(len(population)/2)):\n",
    "            qt_regs_pai1 = population[i][0]\n",
    "            qt_regs_pai2 = population[2*i][0]\n",
    "            \n",
    "            #aqui mistura os regressores\n",
    "            if qt_regs_pai1<=qt_regs_pai2:    \n",
    "                population[i][1][:int(qt_regs_pai1/2)] = population[2*i][1][:int(qt_regs_pai1/2)]\n",
    "            else:\n",
    "                population[i][1][:int(qt_regs_pai2/2)] = population[2*i][1][:int(qt_regs_pai2/2)]\n",
    "                \n",
    "            #modificar nomes dos regressores se houver repetido\n",
    "            nomes = []\n",
    "            for reg in population[i][1]:\n",
    "                while reg[0] in nomes: #adionar X se o nome já estiver dentro\n",
    "                    reg[0] = reg[0]+'X'\n",
    "                nomes.append(reg[0])\n",
    "        \n",
    "        return population\n",
    "    \n",
    "    def early_stop(self):\n",
    "        array = self.fitness_array_\n",
    "        to_break=False\n",
    "        if len(array) > 4:\n",
    "            array_diff1_1 = array[1:] - array[:-1]\n",
    "            array_diff2 = array_diff1_1[1:] - array_diff1_1[:-1]\n",
    "            \n",
    "            if (self.verbose_):\n",
    "                print('second derivative: ', array_diff2[-2:].mean()) \n",
    "                print('first derivative: ', abs(array_diff1_1[-2:].mean()))\n",
    "                print('featness: ', array[-1])\n",
    "                \n",
    "            if (array_diff2[-2:].mean()) > 0 and (abs(array_diff1_1[-3:].mean()) <1e-3):\n",
    "                to_break = True\n",
    "        \n",
    "        return to_break\n",
    "\n",
    "    def search_best(self):\n",
    "        population = self.gen_population()\n",
    "        population = self.set_fitness(population)\n",
    "        population.sort(key = lambda x: x[-1])  \n",
    "        self.fitness_array_ = np.append(self.fitness_array_, population[0][-1])\n",
    "        self.best_of_all_ = population[0][-2]\n",
    "        \n",
    "        for i in tqdm(range(self.epochs)):\n",
    "            population = self.next_population(population)\n",
    "            population = self.set_fitness(population)\n",
    "            population.sort(key = lambda x: x[-1])\n",
    "            \n",
    "            #pegar o melhor de todas as épocas\n",
    "            \n",
    "            if population[0][-1] < min(self.fitness_array_):\n",
    "                self.best_of_all_ = population[0][-2]\n",
    "            \n",
    "            #adicionar ao array de fitness o atual\n",
    "            self.fitness_array_ = np.append(self.fitness_array_, population[0][-1])\n",
    "\n",
    "            if self.early_stop():\n",
    "                break\n",
    "            \n",
    "        return self\n",
    "\n",
    "\n",
    "n_samples = 1000\n",
    "n_outliers = 50\n",
    "X, y, coef = make_regression(n_samples=n_samples, n_features=1,n_informative=1, noise=10,coef=True, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "Ensearch = ensemble_search(X_train, y_train, X_test, y_test, size_pop=10, epochs=50).search_best()\n",
    "print(np.sqrt(mae(Ensearch.best_of_all_.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4761959237016653e-14"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "ridge = Ridge()\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(scale(X), y)\n",
    "    coefs.append(ridge.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([5.00000000e+09, 3.78231664e+09, 2.86118383e+09, 2.16438064e+09,\n",
       "       1.63727458e+09, 1.23853818e+09, 9.36908711e+08, 7.08737081e+08,\n",
       "       5.36133611e+08, 4.05565415e+08, 3.06795364e+08, 2.32079442e+08,\n",
       "       1.75559587e+08, 1.32804389e+08, 1.00461650e+08, 7.59955541e+07,\n",
       "       5.74878498e+07, 4.34874501e+07, 3.28966612e+07, 2.48851178e+07,\n",
       "       1.88246790e+07, 1.42401793e+0...\n",
       "       3.28966612e-01, 2.48851178e-01, 1.88246790e-01, 1.42401793e-01,\n",
       "       1.07721735e-01, 8.14875417e-02, 6.16423370e-02, 4.66301673e-02,\n",
       "       3.52740116e-02, 2.66834962e-02, 2.01850863e-02, 1.52692775e-02,\n",
       "       1.15506485e-02, 8.73764200e-03, 6.60970574e-03, 5.00000000e-03]),\n",
       "        cv=None, fit_intercept=True, gcv_mode=None, normalize=False,\n",
       "        scoring='neg_mean_squared_error', store_cv_values=False)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv = RidgeCV(alphas=alphas, scoring='neg_mean_squared_error')\n",
    "ridgecv.fit(scale(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016213575314855667"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.set_params(alpha=ridgecv.alpha_)\n",
    "ridge.fit(scale(X_train), y_train)\n",
    "sqrt(mean_squared_error(y_test, ridge.predict(scale(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "rfr.fit(scale(X_train), y_train)\n",
    "mean_squared_error(y_test, rfr.predict(scale(X_test)))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(max_depth=10, n_estimators=250, n_jobs=-1, subsample=.7)\n",
    "xgb.fit(scale(X_train), y_train)\n",
    "\n",
    "sqrt(mean_squared_error(y_test, xgb.predict(scale(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1143414524145385"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor(loss= 'ls',max_depth=5, learning_rate=0.01)\n",
    "GBR.fit(scale(X_train), y_train)\n",
    "\n",
    "sqrt(mean_squared_error(y_test, GBR.predict(scale(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x1 = X_test_set.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled1 = min_max_scaler.fit_transform(x1)\n",
    "X_test_set1 = pd.DataFrame(x_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_set1 = X_test_set1.fillna(X_test_set1.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set1 = X_test_set1.fillna((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.277198</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.661001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.259314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232471</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.393258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032160</td>\n",
       "      <td>0.121035</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.521610</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.756678</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269747</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.263579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38986</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.301043</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38987</th>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.769616</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.248882</td>\n",
       "      <td>0.157303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38988</th>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.627713</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38989</th>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.756678</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.178838</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.281195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38990</th>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.464942</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.391952</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.320951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38991 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3    4    5    6     7    8    9  \\\n",
       "0      0.027609  1.000000  0.808989  0.111111  0.0  0.0  0.0  0.75  0.0  0.0   \n",
       "1      0.006675  1.000000  0.808989  0.111111  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "2      0.000000  0.232471  0.842697  0.000000  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "3      0.032160  0.121035  0.707865  0.222222  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "4      0.007888  0.756678  0.775281  0.111111  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "...         ...       ...       ...       ...  ...  ...  ...   ...  ...  ...   \n",
       "38986  0.000000  0.000000  1.000000  0.000000  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "38987  0.004854  0.769616  0.786517  0.111111  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "38988  0.007585  0.627713  0.764045  0.111111  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "38989  0.006068  0.756678  0.775281  0.111111  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "38990  0.003641  0.464942  0.752809  0.111111  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "\n",
       "         10        11        12        13        14  \n",
       "0      0.75  0.277198  0.370787  0.663793  0.661001  \n",
       "1      0.00  0.259314  0.000000  0.000000  0.426165  \n",
       "2      0.00  0.636364  0.393258  0.000000  0.546345  \n",
       "3      0.00  0.521610  0.258427  0.000000  0.523927  \n",
       "4      0.00  0.269747  0.382022  0.896552  0.263579  \n",
       "...     ...       ...       ...       ...       ...  \n",
       "38986  0.00  0.301043  0.134831  0.000000  0.402191  \n",
       "38987  0.00  0.248882  0.157303  0.000000  0.255095  \n",
       "38988  0.00  0.245902  0.078652  0.000000  0.076409  \n",
       "38989  0.00  0.178838  0.247191  0.836207  0.281195  \n",
       "38990  0.00  0.391952  0.112360  0.758621  0.320951  \n",
       "\n",
       "[38991 rows x 15 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df2\n",
    "#test set에 col 추가\n",
    "prediction = lm.predict(X_test_set1)\n",
    "test_set['points'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "5         93.220016\n",
       "14        88.523299\n",
       "15        90.926907\n",
       "18        90.478537\n",
       "21        85.271580\n",
       "            ...    \n",
       "129962    88.043828\n",
       "129964    85.101895\n",
       "129966    81.528181\n",
       "129969    85.623906\n",
       "129970    86.419019\n",
       "Name: points, Length: 38991, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31546120883734563"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(test_set.pre_points,test_set.points ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_excel(\"./result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_excel(\"./cc.xlsx\",index_col=0,parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.dropna(subset = ['points1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.dropna(subset = ['pre_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-5ba0fb6e552f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/dm_env/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[1;32m    240\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 241\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m~/miniconda3/envs/dm_env/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dm_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dm_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "sqrt(mean_squared_error(df3.pre_points,df3.points1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df100 = pd.read_excel(\"./result411.xlsx\",index_col=0,parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6323336576515581"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(df100.points,df100.points1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_env",
   "language": "python",
   "name": "dm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
